"""
ğŸ¤– AI OMR - Scalable Version for Large Classes (500-700 students)
Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙˆØ³Ø¹ Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
"""
import io, base64, time, gc, re
from dataclasses import dataclass
from typing import Dict, List, Optional
import cv2, numpy as np, pandas as pd
import streamlit as st
from pdf2image import convert_from_bytes
from PIL import Image
from datetime import datetime

# OCR for code extraction
try:
    import pytesseract
    HAS_TESSERACT = True
except:
    HAS_TESSERACT = False

# Same helper functions...
def read_bytes(f):
    if not f: return b""
    try: return f.getbuffer().tobytes()
    except: 
        try: return f.read()
        except: return b""

def load_pages(file_bytes, filename, dpi=150):  # Lower DPI: 150 instead of 200
    """Load pages with aggressive memory management"""
    if filename.lower().endswith(".pdf"):
        # Process in smaller chunks
        pages = convert_from_bytes(file_bytes, dpi=dpi, fmt='jpeg', jpegopt={'quality': 85, 'optimize': True})
        return [p.convert("RGB") for p in pages]
    return [Image.open(io.BytesIO(file_bytes)).convert("RGB")]

def pil_to_bgr(pil_img):
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

def bgr_to_bytes(bgr):
    _, buffer = cv2.imencode('.png', bgr, [cv2.IMWRITE_PNG_COMPRESSION, 6])  # Higher compression
    return buffer.tobytes()

# OCR-based code extraction
def extract_code_with_ocr(bgr_image):
    """Extract 4-digit code using OCR (more accurate for numbers)"""
    if not HAS_TESSERACT:
        return None, 0
    
    try:
        h, w = bgr_image.shape[:2]
        
        # ROI for code area (top-left section)
        y1, y2 = int(0.145 * h), int(0.285 * h)
        x1, x2 = int(0.080 * w), int(0.440 * w)
        roi = bgr_image[y1:y2, x1:x2].copy()
        
        # Preprocess
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        gray = clahe.apply(gray)
        gray = cv2.GaussianBlur(gray, (3,3), 0)
        
        # Try multiple thresholds
        variants = []
        
        # Otsu inverse
        _, th1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        variants.append(th1)
        
        # Adaptive mean
        th2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                    cv2.THRESH_BINARY_INV, 31, 7)
        variants.append(th2)
        
        # Adaptive gaussian
        th3 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                    cv2.THRESH_BINARY_INV, 31, 7)
        variants.append(th3)
        
        best_code = None
        best_score = -999
        
        for variant in variants:
            # Upscale for better OCR
            big = cv2.resize(variant, None, fx=2, fy=2, interpolation=cv2.INTER_NEAREST)
            
            # OCR with digit whitelist
            config = "--psm 7 -c tessedit_char_whitelist=0123456789"
            text = pytesseract.image_to_string(big, config=config).strip()
            
            # Extract 4-digit codes
            codes = re.findall(r'\b(1[0-9]{3})\b', text)
            
            if codes:
                code = codes[0]
                code_int = int(code)
                
                # Score based on validity
                score = 50  # base score
                if 1000 <= code_int <= 1999:
                    score += 50
                
                if score > best_score:
                    best_code = code
                    best_score = score
        
        return best_code, best_score
    
    except Exception as e:
        return None, 0

@dataclass
class AIResult:
    answers: Dict
    confidence: str
    notes: List
    success: bool
    student_code: Optional[str] = None

@dataclass
class StudentRecord:
    student_id: str
    name: str
    code: str

@dataclass
class GradingResult:
    student_id: str
    name: str
    detected_code: str
    score: int
    total: int
    page_number: int = 0

def analyze_with_ai(image_bytes, api_key, is_answer_key=True):
    """AI Analysis - optimized"""
    if not api_key or len(api_key) < 20:
        return AIResult({}, "no_api", ["API Key required"], False)
    
    try:
        import anthropic
        client = anthropic.Anthropic(api_key=api_key)
        
        image_b64 = base64.b64encode(image_bytes).decode('utf-8')
        
        if is_answer_key:
            prompt = """Read the ANSWER KEY sheet carefully.

This is the CORRECT ANSWERS sheet (not a student sheet).
It shows the right answer for each question.

There are 10 questions, each with 4 choices: A, B, C, D
One bubble is filled for each question - that's the correct answer.

Read the filled bubble for each question (1-10).

RESPOND WITH JSON ONLY:
{
  "answers": {
    "1": "C",
    "2": "B",
    "3": "A",
    "4": "D",
    "5": "A",
    "6": "C",
    "7": "B",
    "8": "D",
    "9": "A",
    "10": "B"
  }
}"""
        else:
            prompt = """You are an expert OMR (Optical Mark Recognition) system. Read this student answer sheet with EXTREME precision.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ STUDENT CODE GRID (TOP OF PAGE) - READ WITH EXTREME CARE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

The code grid has FOUR VERTICAL COLUMNS (reading LEFT to RIGHT):

COLUMN 1 (First digit):    â“ª â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ â‘¦ â‘§ â‘¨
COLUMN 2 (Second digit):   â“ª â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ â‘¦ â‘§ â‘¨
COLUMN 3 (Third digit):    â“ª â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ â‘¦ â‘§ â‘¨
COLUMN 4 (Fourth digit):   â“ª â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ â‘¦ â‘§ â‘¨

CRITICAL INSTRUCTIONS:
1. Look at EACH COLUMN separately - treat each like an independent question
2. Find the FILLED/DARKEST bubble in each column
3. The code MUST start with "1" (first column = 1)
4. Valid range: 1000-1057
5. Output EXACTLY 4 digits - no more, no less

COMMON MISTAKES TO AVOID:
âŒ Confusing 0 â†” 8 (zero vs eight)
âŒ Confusing 1 â†” 7 (one vs seven)  
âŒ Confusing 3 â†” 8 (three vs eight)
âŒ Confusing 5 â†” 6 (five vs six)
âŒ Confusing 7 â†” 9 (seven vs nine)
âŒ Reading wrong column order

STEP-BY-STEP PROCESS:
Step 1: Locate the code grid (top-left area of page)
Step 2: Read Column 1 â†’ Find filled bubble â†’ Usually "1"
Step 3: Read Column 2 â†’ Find filled bubble â†’ 0-9
Step 4: Read Column 3 â†’ Find filled bubble â†’ 0-9
Step 5: Read Column 4 â†’ Find filled bubble â†’ 0-9
Step 6: Combine: [digit1][digit2][digit3][digit4]

EXAMPLE:
Column 1: Bubble â‘  is filled â†’ "1"
Column 2: Bubble â“ª is filled â†’ "0"
Column 3: Bubble â‘  is filled â†’ "1"
Column 4: Bubble â‘¦ is filled â†’ "7"
Final code = "1017" âœ…

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ ANSWERS (10 Questions: A, B, C, D)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

RULE 1 - X mark CANCELS a bubble (HIGHEST PRIORITY):
Q1: [â—X] A  [â—] B  [ ] C  [ ] D
    ^^^^    ^^^
  CANCEL   ANSWER
â†’ Ignore A (has X mark)
â†’ Answer: B âœ…

RULE 2 - Single filled bubble:
Q2: [ ] A  [â—] B  [ ] C  [ ] D
â†’ Answer: B âœ…

RULE 3 - Multiple filled bubbles (NO X marks):
Q3: [â—â—] A  [â—] B  [ ] C  [ ] D
    ^^^^    ^^^
   DARKER  LIGHTER
â†’ Answer: A (darkest) âœ…

ALGORITHM:
1. Remove any bubble with X mark
2. From remaining: choose DARKEST
3. If none: "?"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

RESPOND WITH JSON ONLY (no extra text):
{
  "col1": "1",
  "col2": "0",
  "col3": "1",
  "col4": "7",
  "student_code": "1017",
  "answers": {
    "1": "C",
    "2": "B",
    "3": "A",
    "4": "D",
    "5": "A",
    "6": "C",
    "7": "B",
    "8": "D",
    "9": "A",
    "10": "B"
  }
}"""
        
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1500,
            messages=[{
                "role": "user",
                "content": [
                    {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": image_b64}},
                    {"type": "text", "text": prompt}
                ]
            }]
        )
        
        response_text = message.content[0].text
        
        import json, re
        json_text = response_text
        if "```json" in response_text:
            json_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            json_text = response_text.split("```")[1].split("```")[0].strip()
        
        try:
            result = json.loads(json_text)
        except:
            match = re.search(r'\{[\s\S]*\}', response_text)
            if match: result = json.loads(match.group())
            else: raise ValueError("No JSON")
        
        answers = {int(k): v for k, v in result.get("answers", {}).items()}
        student_code = result.get("student_code") if not is_answer_key else None
        
        return AIResult(answers, result.get("confidence", "medium"), result.get("notes", []), True, student_code)
    
    except Exception as e:
        return AIResult({}, "error", [str(e)], False)

def load_students_from_excel(file_bytes):
    """Load students from Excel"""
    try:
        df = pd.read_excel(io.BytesIO(file_bytes))
        id_col = name_col = code_col = None
        for col in df.columns:
            cl = str(col).lower().strip()
            if 'id' in cl or 'Ø±Ù‚Ù…' in cl: id_col = col
            elif 'name' in cl or 'Ø§Ø³Ù…' in cl: name_col = col
            elif 'code' in cl or 'ÙƒÙˆØ¯' in cl or 'Ø±Ù…Ø²' in cl: code_col = col
        
        if not all([id_col, name_col, code_col]):
            return []
        
        students = []
        for _, row in df.iterrows():
            students.append(StudentRecord(str(row[id_col]), str(row[name_col]), str(row[code_col])))
        return students
    except Exception as e:
        st.error(f"Excel error: {e}")
        return []

def find_student_by_code(students, code):
    """Find student with flexible matching"""
    code_norm = str(code).strip().replace(" ", "").replace("-", "")
    for s in students:
        s_code = str(s.code).strip().replace(" ", "").replace("-", "")
        if s_code == code_norm: return s
    
    # Try prefix match (if code is longer)
    if len(code_norm) > 4:
        for length in [4, 5, 6]:
            if len(code_norm) >= length:
                prefix = code_norm[:length]
                for s in students:
                    s_code = str(s.code).strip().replace(" ", "").replace("-", "")
                    if s_code == prefix: return s
    return None

def grade_student(student_answers, answer_key):
    """Grade student"""
    score = sum(1 for q in answer_key.keys() if student_answers.get(q) == answer_key[q])
    return score, len(answer_key)

def export_results(results):
    """Export to Excel - minimal format"""
    data = [{
        "Page": r.page_number,
        "ID": r.student_id, 
        "Name": r.name, 
        "Code": r.detected_code, 
        "Score": r.score
    } for r in results]
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        pd.DataFrame(data).to_excel(writer, sheet_name='Results', index=False)
    return output.getvalue()

# ==== MAIN APP ====
def main():
    st.set_page_config(page_title="ğŸ¤– AI OMR - Scalable", layout="wide")
    st.title("ğŸ¤– Ù†Ø¸Ø§Ù… OMR Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©")
    st.markdown("### ğŸ“Š 500-700 Ø·Ø§Ù„Ø¨ Ø¨Ø¯ÙˆÙ† Ù…Ø´Ø§ÙƒÙ„!")
    
    # Session state
    if 'answer_key' not in st.session_state: st.session_state.answer_key = {}
    if 'students' not in st.session_state: st.session_state.students = []
    if 'results' not in st.session_state: st.session_state.results = []
    if 'processed_pages' not in st.session_state: st.session_state.processed_pages = set()
    if 'duplicate_warnings' not in st.session_state: st.session_state.duplicate_warnings = []
    if 'allow_duplicates' not in st.session_state: st.session_state.allow_duplicates = False
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        api_key = ""
        try:
            api_key = st.secrets.get("ANTHROPIC_API_KEY", "")
            if api_key: st.success("âœ… API Key")
        except: pass
        if not api_key:
            api_key = st.text_input("ğŸ”‘ API Key", type="password")
        
        st.markdown("---")
        st.metric("Answer Key", f"{len(st.session_state.answer_key)} Q")
        st.metric("Students", len(st.session_state.students))
        st.metric("Graded", len(st.session_state.results))
        
        if st.session_state.results:
            avg = np.mean([r.score/r.total*100 for r in st.session_state.results])
            st.metric("Average", f"{avg:.1f}%")
        
        if st.button("ğŸ”„ Reset All", type="secondary"):
            st.session_state.answer_key = {}
            st.session_state.results = []
            st.session_state.processed_pages = set()
            st.rerun()
    
    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs(["1ï¸âƒ£ Answer Key", "2ï¸âƒ£ Students", "3ï¸âƒ£ Grade", "4ï¸âƒ£ Results"])
    
    # TAB 1: Answer Key
    with tab1:
        st.subheader("ğŸ“ Answer Key")
        key_file = st.file_uploader("Upload Answer Key", type=["pdf","png","jpg"], key="key")
        if key_file:
            if st.button("ğŸ¤– Analyze", type="primary"):
                if not api_key: 
                    st.error("âŒ Need API Key")
                else:
                    with st.spinner("Analyzing..."):
                        b = read_bytes(key_file)
                        pages = load_pages(b, key_file.name, 200)
                        if pages:
                            img = bgr_to_bytes(pil_to_bgr(pages[0]))
                            res = analyze_with_ai(img, api_key, True)
                            if res.success:
                                st.session_state.answer_key = res.answers
                                st.success(f"âœ… {len(res.answers)} questions")
                            else: st.error("Failed")
        
        if st.session_state.answer_key:
            st.info(" | ".join([f"Q{q}: {a}" for q, a in sorted(st.session_state.answer_key.items())]))
    
    # TAB 2: Students
    with tab2:
        st.subheader("ğŸ‘¥ Students")
        excel = st.file_uploader("Upload Excel (ID, Name, Code)", type=["xlsx","xls"], key="excel")
        if excel and st.button("ğŸ“Š Load"):
            students = load_students_from_excel(read_bytes(excel))
            if students:
                st.session_state.students = students
                st.success(f"âœ… {len(students)} students")
        
        if st.session_state.students:
            st.info(f"Loaded: {len(st.session_state.students)} students")
            with st.expander("View Students"):
                df = pd.DataFrame([{"ID": s.student_id, "Name": s.name, "Code": s.code} 
                                   for s in st.session_state.students[:50]])
                st.dataframe(df)
    
    # TAB 3: Grading
    with tab3:
        st.subheader("âœ… Grading - Optimized for Large Scale")
        
        if not st.session_state.answer_key:
            st.warning("âš ï¸ Load Answer Key first")
            return
        if not st.session_state.students:
            st.warning("âš ï¸ Load Students first")
            return
        
        st.info("""
        ğŸ’¡ **Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (500-700 Ø·Ø§Ù„Ø¨):**
        
        **Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§:**
        1. Ù‚Ø³Ù‘Ù… PDF Ø§Ù„ÙƒØ¨ÙŠØ± Ù„Ù…Ù„ÙØ§Øª Ø£ØµØºØ± (**30-50 ÙˆØ±Ù‚Ø© Ù„ÙƒÙ„ Ù…Ù„Ù** - Ù…Ù‡Ù…!)
        2. Ø§Ø±ÙØ¹ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©
        3. Ø¹Ø§Ù„Ø¬ 10-20 ÙˆØ±Ù‚Ø© ÙÙŠ ÙƒÙ„ Ø¯ÙØ¹Ø©
        4. Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØªØªØ¬Ù…Ø¹ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        5. Ø§Ø³ØªØ®Ø¯Ù… AI Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¨Ø¯Ù‚Ø©
        
        âš ï¸ **Ù„ØªØ¬Ù†Ø¨ Memory Error:**
        - Ù„Ø§ ØªØ±ÙØ¹ Ù…Ù„ÙØ§Øª Ø£ÙƒØ¨Ø± Ù…Ù† 50 ØµÙØ­Ø©
        - Ø§Ø³ØªØ®Ø¯Ù… batch size ØµØºÙŠØ± (10-20)
        - Ù„Ùˆ Ø¸Ù‡Ø± Ø®Ø·Ø£ memory: Ø§Ø¶ØºØ· "Reboot" ÙˆØ£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ù…Ù„ÙØ§Øª Ø£ØµØºØ±
        
        **Ù…Ø«Ø§Ù„:** 500 Ø·Ø§Ù„Ø¨
        - Ù‚Ø³Ù‘Ù… Ù„Ù€ 10 Ù…Ù„ÙØ§Øª (50 ÙˆØ±Ù‚Ø© Ù„ÙƒÙ„ Ù…Ù„Ù)
        - ÙƒÙ„ Ù…Ù„Ù: 5 Ø¯ÙØ¹Ø§Øª Ã— 10 Ø£ÙˆØ±Ø§Ù‚ = 3-4 Ø¯Ù‚Ø§Ø¦Ù‚
        - Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: 30-40 Ø¯Ù‚ÙŠÙ‚Ø© âœ…
        
        **Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:** 10 Ù…Ù„ÙØ§Øª Ã— 3-4 Ø¯Ù‚Ø§Ø¦Ù‚ = 30-40 Ø¯Ù‚ÙŠÙ‚Ø©
        **Ø§Ù„ØªÙƒÙ„ÙØ©:** 500 Ã— $0.003 = $1.50
        """)
        
        sheets = st.file_uploader(
            "Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF (âš ï¸ **Ø£Ù‚ØµÙ‰ Ø­Ø¯: 50 ØµÙØ­Ø©**)",
            type=["pdf"],
            accept_multiple_files=False,
            key="sheets"
        )
        
        st.warning("âš ï¸ **Ø­Ø¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø©:** Ù„Ø§ ØªØ±ÙØ¹ Ù…Ù„ÙØ§Øª Ø£ÙƒØ¨Ø± Ù…Ù† 50 ØµÙØ­Ø©! Ù‚Ø³Ù‘Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø£ÙˆÙ„Ø§Ù‹.")
        
        col1, col2 = st.columns(2)
        with col1:
            batch_size = st.slider("ğŸ“¦ Batch size", 5, 20, 10, help="Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø©: Ø§Ø³ØªØ®Ø¯Ù… 10 Ø£Ùˆ Ø£Ù‚Ù„")
        with col2:
            auto_continue = st.checkbox("ğŸ”„ Auto-continue", value=False, help="âš ï¸ Ø£Ø·ÙØ¦Ù‡ Ù„Ùˆ ÙÙŠ Ù…Ø´Ø§ÙƒÙ„ Ø°Ø§ÙƒØ±Ø©")
        
        st.markdown("---")
        st.subheader("ğŸ” Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª")
        
        dup_mode = st.radio(
            "ÙƒÙŠÙ ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…ÙƒØ±Ø±Ø©ØŸ",
            options=[
                "âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙ‚Ø· (ØµØ­Ø­ Ø§Ù„Ø¬Ù…ÙŠØ¹)",
                "ğŸš« ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª (ØµØ­Ø­ Ø§Ù„Ø£ÙˆÙ„ ÙÙ‚Ø·)",
                "âœ… Ù„Ø§ ØªÙØ­Øµ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª (ØµØ­Ø­ ÙƒÙ„ Ø´ÙŠØ¡)"
            ],
            help="""
            **ØªØ­Ø°ÙŠØ± ÙÙ‚Ø·:** ÙŠØµØ­Ø­ ÙƒÙ„ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ ÙˆÙŠØ¹Ø·ÙŠÙƒ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…ÙƒØ±Ø±Ø©
            **ØªØ¬Ø§Ù‡Ù„:** ÙŠØµØ­Ø­ Ø£ÙˆÙ„ ÙˆØ±Ù‚Ø© ÙÙ‚Ø· ÙˆÙŠØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¨Ø§Ù‚ÙŠ
            **Ù„Ø§ ØªÙØ­Øµ:** ÙŠØµØ­Ø­ ÙƒÙ„ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø¹Ù†Ø¯Ùƒ Ø·Ù„Ø§Ø¨ Ø¨Ù†ÙØ³ Ø§Ù„ÙƒÙˆØ¯)
            """
        )
        
        if st.session_state.duplicate_warnings:
            st.warning(f"âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(st.session_state.duplicate_warnings)} ÙƒÙˆØ¯ Ù…ÙƒØ±Ø±!")
            with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…ÙƒØ±Ø±Ø©"):
                for dup in st.session_state.duplicate_warnings:
                    st.error(f"Ø§Ù„ÙƒÙˆØ¯ {dup['code']} - Ø§Ù„ØµÙØ­Ø§Øª: {', '.join(map(str, dup['pages']))}")
        
        if sheets and 'current_file_pages' not in st.session_state:
            if st.button("ğŸ” Load File"):
                with st.spinner("Loading file..."):
                    b = read_bytes(sheets)
                    pages = load_pages(b, sheets.name, 200)
                    st.session_state.current_file_pages = pages
                    st.session_state.current_file_idx = 0
                    st.success(f"âœ… Loaded {len(pages)} pages from {sheets.name}")
        
        if 'current_file_pages' in st.session_state:
            pages = st.session_state.current_file_pages
            current = st.session_state.current_file_idx
            total = len(pages)
            remaining = total - current
            
            st.metric("File Progress", f"{current}/{total} ({current/total*100:.0f}%)")
            
            if remaining > 0:
                if st.button(f"ğŸš€ Process next {min(batch_size, remaining)}", type="primary") or auto_continue:
                    end = min(current + batch_size, total)
                    
                    progress = st.progress(0)
                    status = st.empty()
                    
                    processed_count = 0
                    
                    for i in range(current, end):
                        rel = i - current
                        status.text(f"Page {i+1}/{total} ({rel+1}/{end-current})")
                        progress.progress((rel+1)/(end-current))
                        
                        # Skip if already processed
                        if i in st.session_state.processed_pages:
                            status.text(f"â­ï¸ Page {i+1} already processed")
                            continue
                        
                        page = pages[i]
                        
                        # Convert and compress immediately
                        bgr = pil_to_bgr(page)
                        
                        # Extract code with AI (simple and reliable)
                        img = bgr_to_bytes(bgr)
                        res = analyze_with_ai(img, api_key, False)
                        
                        if not res.success or not res.student_code:
                            st.warning(f"âš ï¸ Page {i+1}: Failed to read")
                            del page, bgr, img
                            continue
                        
                        code = res.student_code.strip()
                        
                        # CRITICAL: Double-check if code seems wrong
                        needs_recheck = False
                        recheck_reason = ""
                        
                        if len(code) == 4 and code.isdigit():
                            code_int = int(code)
                            
                            # Suspicious patterns that need double-check
                            if code[0] == '0':
                                needs_recheck = True
                                recheck_reason = "starts with 0"
                            elif code_int > 1057:
                                needs_recheck = True
                                recheck_reason = "out of range"
                            elif not find_student_by_code(st.session_state.students, code):
                                needs_recheck = True
                                recheck_reason = "not in student list"
                        else:
                            needs_recheck = True
                            recheck_reason = "invalid format"
                        
                        # DOUBLE-CHECK: Re-read with ultra-detailed prompt
                        if needs_recheck:
                            st.warning(f"ğŸ” Page {i+1}: Code {code} suspicious ({recheck_reason}) - double-checking...")
                            
                            # Ultra-detailed prompt focusing ONLY on code
                            detailed_prompt = """âš ï¸ CRITICAL RE-CHECK: Student Code Grid Reading

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ FOCUS: CODE GRID ONLY (top-left area of page)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Look VERY CAREFULLY at the bubble grid. It has 4 VERTICAL COLUMNS:

COLUMN 1 (1st digit):  â“ª â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ â‘¦ â‘§ â‘¨  â†’ Which bubble is FILLED?
COLUMN 2 (2nd digit):  â“ª â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ â‘¦ â‘§ â‘¨  â†’ Which bubble is FILLED?
COLUMN 3 (3rd digit):  â“ª â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ â‘¦ â‘§ â‘¨  â†’ Which bubble is FILLED?
COLUMN 4 (4th digit):  â“ª â‘  â‘¡ â‘¢ â‘£ â‘¤ â‘¥ â‘¦ â‘§ â‘¨  â†’ Which bubble is FILLED?

âš ï¸ CRITICAL WARNINGS:
â€¢ First column MUST be "1" (not 0, not 7)
â€¢ Valid codes: 1000-1057 ONLY
â€¢ Watch for similar-looking numbers:
  - 0 vs 8 (zero vs eight)
  - 1 vs 7 (one vs seven)
  - 3 vs 8 (three vs eight)
  - 5 vs 6 (five vs six)
  - 7 vs 9 (seven vs nine)

VERIFICATION STEPS:
1. Find the grid (top-left area)
2. Read Column 1 carefully â†’ Usually "1"
3. Read Column 2 carefully â†’ 0-9
4. Read Column 3 carefully â†’ 0-9
5. Read Column 4 carefully â†’ 0-9
6. Double-check: Does it look reasonable?
7. Verify: Is it between 1000-1057?

JSON ONLY:
{
  "col1": "1",
  "col2": "0",
  "col3": "1",
  "col4": "7",
  "student_code": "1017",
  "confidence": "high"
}"""
                            
                            # Second attempt with ultra-detailed prompt
                            import anthropic
                            client = anthropic.Anthropic(api_key=api_key)
                            image_b64 = base64.b64encode(img).decode('utf-8')
                            
                            message = client.messages.create(
                                model="claude-sonnet-4-20250514",
                                max_tokens=500,
                                messages=[{
                                    "role": "user",
                                    "content": [
                                        {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": image_b64}},
                                        {"type": "text", "text": detailed_prompt}
                                    ]
                                }]
                            )
                            
                            # Parse second attempt
                            try:
                                import json
                                text = message.content[0].text
                                # Remove markdown if present
                                if '```' in text:
                                    text = text.split('```')[1]
                                    if text.startswith('json'):
                                        text = text[4:]
                                text = text.strip()
                                
                                data = json.loads(text)
                                new_code = data.get('student_code', '').strip()
                                
                                if new_code and new_code != code:
                                    st.info(f"ğŸ”„ Page {i+1}: Double-check changed code: {code} â†’ {new_code}")
                                    code = new_code
                                    res.student_code = new_code
                                else:
                                    st.warning(f"âš ï¸ Page {i+1}: Double-check confirmed: {code} (may need manual review)")
                            except:
                                st.error(f"âŒ Page {i+1}: Double-check failed - keeping original: {code}")
                        
                        # Free memory immediately after AI processing
                        del page, bgr, img
                        
                        # Force garbage collection every 10 pages
                        if (i - current) % 10 == 0:
                            gc.collect()
                        
                        # Strict validation
                        if not code.isdigit():
                            st.warning(f"âš ï¸ Page {i+1}: Bad code '{code}' (contains non-digits)")
                            continue
                        
                        if len(code) != 4:
                            st.warning(f"âš ï¸ Page {i+1}: Bad code '{code}' (must be exactly 4 digits, got {len(code)})")
                            continue
                        
                        code_int = int(code)
                        if code_int < 1000 or code_int > 1999:
                            st.warning(f"âš ï¸ Page {i+1}: Code {code} out of range (expected 1000-1999)")
                            continue
                        
                        student = find_student_by_code(st.session_state.students, code)
                        if not student:
                            st.warning(f"âš ï¸ Page {i+1}: Code {code} not found in student list")
                            continue
                        
                        # Check for duplicates based on mode
                        already_graded = any(r.detected_code == code for r in st.session_state.results)
                        
                        if already_graded:
                            if "ØªØ¬Ø§Ù‡Ù„" in dup_mode:
                                # Mode 2: Skip duplicates
                                st.info(f"â„¹ï¸ Page {i+1}: Code {code} ({student.name}) already graded - skipping")
                                st.session_state.processed_pages.add(i)
                                continue
                            elif "ØªØ­Ø°ÙŠØ±" in dup_mode:
                                # Mode 1: Warn but continue grading
                                st.warning(f"âš ï¸ Page {i+1}: Code {code} is DUPLICATE - grading anyway")
                                
                                # Track duplicate
                                existing_dup = next((d for d in st.session_state.duplicate_warnings if d['code'] == code), None)
                                if existing_dup:
                                    existing_dup['pages'].append(i+1)
                                else:
                                    st.session_state.duplicate_warnings.append({
                                        'code': code,
                                        'name': student.name,
                                        'pages': [i+1]
                                    })
                            # Mode 3: No check - continues automatically
                        
                        score, total_q = grade_student(res.answers, st.session_state.answer_key)
                        
                        st.session_state.results.append(GradingResult(
                            student.student_id, student.name, code, score, total_q, i+1
                        ))
                        
                        st.session_state.processed_pages.add(i)
                        processed_count += 1
                        
                        status.text(f"âœ… Page {i+1}: {code} - {student.name} ({score}/{total_q})")
                    
                    st.session_state.current_file_idx = end
                    
                    # Aggressive memory cleanup
                    if end >= total:
                        # File complete - clear everything
                        del st.session_state.current_file_pages
                        del st.session_state.current_file_idx
                        gc.collect()
                    
                    gc.collect()
                    
                    st.success(f"âœ… Processed {processed_count} pages")
                    
                    if end >= total:
                        st.balloons()
                        st.success("ğŸ‰ File complete!")
                    elif auto_continue:
                        time.sleep(0.5)
                        st.rerun()
            else:
                st.success("File complete! Upload next file or go to Results.")
    
    # TAB 4: Results
    with tab4:
        st.subheader("ğŸ“Š Results")
        
        if not st.session_state.results:
            st.info("No results yet")
            return
        
        # Duplicate warnings section
        if st.session_state.duplicate_warnings:
            st.error(f"âš ï¸ **ØªØ­Ø°ÙŠØ±: ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(st.session_state.duplicate_warnings)} ÙƒÙˆØ¯ Ù…ÙƒØ±Ø±!**")
            
            with st.expander("ğŸ” ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…ÙƒØ±Ø±Ø©", expanded=True):
                st.markdown("""
                **Ù‡Ø°Ù‡ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø¸Ù‡Ø±Øª ÙÙŠ Ø£ÙƒØ«Ø± Ù…Ù† ÙˆØ±Ù‚Ø©:**
                - Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø·Ø§Ù„Ø¨ ÙƒØªØ¨ ÙƒÙˆØ¯ Ø²Ù…ÙŠÙ„Ù‡ Ø¨Ø§Ù„Ø®Ø·Ø£
                - Ø±Ø§Ø¬Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ ÙŠØ¯ÙˆÙŠØ§Ù‹
                - ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª ÙˆØ§Ù„Ø®Ø·
                """)
                
                for dup in st.session_state.duplicate_warnings:
                    st.warning(f"""
                    **Ø§Ù„ÙƒÙˆØ¯:** {dup['code']} - **Ø§Ù„Ø§Ø³Ù…:** {dup['name']}  
                    **Ø¸Ù‡Ø± ÙÙŠ Ø§Ù„ØµÙØ­Ø§Øª:** {', '.join(map(str, dup['pages']))}  
                    **Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª:** {len(dup['pages'])} Ù…Ø±Ø©
                    """)
                
                # Show affected results
                dup_codes = [d['code'] for d in st.session_state.duplicate_warnings]
                dup_results = [r for r in st.session_state.results if r.detected_code in dup_codes]
                
                if dup_results:
                    st.markdown("**Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©:**")
                    dup_df = pd.DataFrame([{
                        "Page": r.page_number,
                        "Code": r.detected_code,
                        "Name": r.name,
                        "Score": r.score
                    } for r in dup_results])
                    st.dataframe(dup_df, width='stretch')
            
            st.markdown("---")
        
        scores = [r.score/r.total*100 for r in st.session_state.results]
        col1, col2, col3, col4 = st.columns(4)
        with col1: st.metric("Graded", len(scores))
        with col2: st.metric("Average", f"{np.mean(scores):.1f}%")
        with col3: st.metric("Max", f"{np.max(scores):.1f}%")
        with col4: st.metric("Min", f"{np.min(scores):.1f}%")
        
        df = pd.DataFrame([{
            "Page": r.page_number,
            "ID": r.student_id, 
            "Name": r.name, 
            "Code": r.detected_code,
            "Score": r.score,
            "%": f"{r.score/r.total*100:.0f}"
        } for r in st.session_state.results])
        
        st.dataframe(df, width='stretch')
        
        # Duplicate cleaning options
        if st.session_state.duplicate_warnings:
            st.markdown("---")
            st.subheader("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª")
            
            clean_method = st.radio(
                "ÙƒÙŠÙ ØªØ±ÙŠØ¯ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§ØªØŸ",
                options=[
                    "Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£ÙˆÙ„ ÙÙ‚Ø·",
                    "Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø©",
                    "Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£Ù‚Ù„ Ø¯Ø±Ø¬Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)",
                    "Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø¬Ù…ÙŠØ¹ (Excel Ø³ÙŠØ¸Ù‡Ø± ÙƒÙ„Ù‡Ù…)"
                ]
            )
            
            if st.button("ğŸ§¹ Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªØ§Ø¦Ø¬ Ù†Ø¸ÙŠÙØ©"):
                if "Ø§Ù„Ø£ÙˆÙ„" in clean_method:
                    # Keep first occurrence
                    clean_results = []
                    seen_codes = set()
                    for r in sorted(st.session_state.results, key=lambda x: x.page_number):
                        if r.detected_code not in seen_codes:
                            clean_results.append(r)
                            seen_codes.add(r.detected_code)
                    st.success(f"âœ… ØªÙ…! {len(clean_results)} Ù†ØªÙŠØ¬Ø© Ù†Ø¸ÙŠÙØ© (Ø­Ø°Ù {len(st.session_state.results) - len(clean_results)} ØªÙƒØ±Ø§Ø±)")
                    st.session_state.clean_results = clean_results
                
                elif "Ø§Ù„Ø£Ø¹Ù„Ù‰" in clean_method:
                    # Keep highest score
                    from collections import defaultdict
                    by_code = defaultdict(list)
                    for r in st.session_state.results:
                        by_code[r.detected_code].append(r)
                    
                    clean_results = []
                    for code, results in by_code.items():
                        best = max(results, key=lambda x: x.score)
                        clean_results.append(best)
                    st.success(f"âœ… ØªÙ…! {len(clean_results)} Ù†ØªÙŠØ¬Ø© (Ø£ÙØ¶Ù„ Ø¯Ø±Ø¬Ø© Ù„ÙƒÙ„ ÙƒÙˆØ¯)")
                    st.session_state.clean_results = clean_results
                
                elif "Ø§Ù„Ø£Ù‚Ù„" in clean_method:
                    # Keep lowest score (for review)
                    from collections import defaultdict
                    by_code = defaultdict(list)
                    for r in st.session_state.results:
                        by_code[r.detected_code].append(r)
                    
                    clean_results = []
                    for code, results in by_code.items():
                        worst = min(results, key=lambda x: x.score)
                        clean_results.append(worst)
                    st.success(f"âœ… ØªÙ…! {len(clean_results)} Ù†ØªÙŠØ¬Ø© (Ø£Ù‚Ù„ Ø¯Ø±Ø¬Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)")
                    st.session_state.clean_results = clean_results
                
                else:
                    # Keep all
                    st.session_state.clean_results = st.session_state.results
        
        # Export buttons
        st.markdown("---")
        results_to_export = st.session_state.get('clean_results', st.session_state.results)
        
        if st.button("ğŸ“¥ Export Excel", type="primary"):
            excel = export_results(results_to_export)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            status_text = f"({len(results_to_export)} Ù†ØªÙŠØ¬Ø©"
            if 'clean_results' in st.session_state and len(results_to_export) < len(st.session_state.results):
                status_text += f" - ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(st.session_state.results) - len(results_to_export)} ØªÙƒØ±Ø§Ø±"
            status_text += ")"
            
            st.download_button(
                f"â¬‡ï¸ Download {status_text}", 
                excel, 
                f"results_{ts}.xlsx", 
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

if __name__ == "__main__":
    main()
