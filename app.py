# app.py
import io
import traceback
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional

import cv2
import numpy as np
import pandas as pd
import streamlit as st
from pdf2image import convert_from_bytes
from PIL import Image


# =========================
# Safe converters
# =========================
def safe_float(x) -> float:
    if isinstance(x, (list, tuple)):
        x = np.array(x)
    if isinstance(x, np.ndarray):
        x = x.ravel()
        return float(x[0]) if x.size else 0.0
    try:
        return float(x)
    except Exception:
        return 0.0


def safe_int(x) -> int:
    return int(round(safe_float(x)))


# =========================
# IO helpers
# =========================
def read_bytes(uploaded_file) -> bytes:
    if uploaded_file is None:
        return b""
    try:
        return uploaded_file.getbuffer().tobytes()
    except Exception:
        try:
            return uploaded_file.read()
        except Exception:
            return b""


def load_pages(file_bytes: bytes, filename: str, dpi: int = 300) -> List[Image.Image]:
    if filename.lower().endswith(".pdf"):
        pages = convert_from_bytes(file_bytes, dpi=dpi)
        return [p.convert("RGB") for p in pages]
    return [Image.open(io.BytesIO(file_bytes)).convert("RGB")]


def pil_to_bgr(pil_img: Image.Image) -> np.ndarray:
    arr = np.array(pil_img)
    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)


def bgr_to_rgb(bgr: np.ndarray) -> np.ndarray:
    return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)


# =========================
# Data models
# =========================
@dataclass
class BubbleGrid:
    row_y: np.ndarray      # (R,)
    col_x: np.ndarray      # (C,)
    centers: np.ndarray    # (R,C,2)
    rows: int
    cols: int


@dataclass
class LearnedTemplate:
    ref_bgr: np.ndarray
    ref_w: int
    ref_h: int
    id_grid: BubbleGrid
    q_grid: BubbleGrid
    num_q: int
    num_choices: int
    id_rows: int = 10
    id_digits: int = 4


# =========================
# Preprocess
# =========================
def preprocess_binary(bgr: np.ndarray) -> np.ndarray:
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)
    bin_img = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV, 31, 7
    )
    bin_img = cv2.medianBlur(bin_img, 3)
    return bin_img


# =========================
# Bubble center detection (robust, auto)
# =========================
def find_bubble_centers(bin_img: np.ndarray) -> np.ndarray:
    cnts, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        return np.zeros((0, 2), dtype=np.int32)

    records = []
    for c in cnts:
        area = cv2.contourArea(c)
        if area < 20:
            continue
        peri = cv2.arcLength(c, True)
        if peri < 20:
            continue
        circ = 4.0 * np.pi * area / (peri * peri + 1e-6)
        x, y, w, h = cv2.boundingRect(c)
        ar = w / (h + 1e-6)
        records.append((area, circ, ar, c))

    if not records:
        return np.zeros((0, 2), dtype=np.int32)

    # learn typical sizes
    areas = np.array([r[0] for r in records], dtype=np.float32)
    loga = np.log(np.clip(areas, 1, None))
    hist, edges = np.histogram(loga, bins=25)
    peak = int(np.argmax(hist))
    lo = float(edges[peak])
    hi = float(edges[min(peak + 1, len(edges) - 1)])

    area_lo = float(np.exp(lo)) * 0.5
    area_hi = float(np.exp(hi)) * 2.5

    centers = []
    for area, circ, ar, c in records:
        if not (area_lo <= area <= area_hi):
            continue
        if circ < 0.18:
            continue
        if not (0.55 <= ar <= 1.80):
            continue
        M = cv2.moments(c)
        if abs(M["m00"]) < 1e-6:
            continue
        cx = safe_int(M["m10"] / M["m00"])
        cy = safe_int(M["m01"] / M["m00"])
        centers.append((cx, cy))

    return np.array(centers, dtype=np.int32) if centers else np.zeros((0, 2), dtype=np.int32)


# =========================
# Clustering helpers (no sklearn)
# =========================
def robust_gap_tolerance(sorted_vals: np.ndarray) -> float:
    if len(sorted_vals) < 6:
        return 10.0
    diffs = np.diff(sorted_vals)
    diffs = diffs[diffs > 0]
    if len(diffs) == 0:
        return 10.0
    p10 = np.percentile(diffs, 10)
    p40 = np.percentile(diffs, 40)
    small = diffs[(diffs >= p10) & (diffs <= p40)]
    base = float(np.median(small)) if len(small) else float(np.median(diffs))
    return max(6.0, base * 0.70)


def group_1d_positions(values: np.ndarray) -> np.ndarray:
    v = np.sort(values.astype(np.float32))
    if len(v) == 0:
        return np.array([], dtype=np.float32)
    tol = robust_gap_tolerance(v)
    groups = []
    cur = [v[0]]
    for x in v[1:]:
        if (x - cur[-1]) <= tol:
            cur.append(x)
        else:
            groups.append(cur)
            cur = [x]
    groups.append(cur)
    centers = np.array([float(np.mean(g)) for g in groups], dtype=np.float32)
    return np.sort(centers)


def snap_to_grid(centers_xy: np.ndarray, row_y: np.ndarray, col_x: np.ndarray) -> np.ndarray:
    R = len(row_y)
    C = len(col_x)
    grid = np.zeros((R, C, 2), dtype=np.float32)
    cnt = np.zeros((R, C), dtype=np.int32)

    for xy in centers_xy:
        x = float(xy[0]); y = float(xy[1])
        ri = int(np.argmin(np.abs(row_y - y)))
        ci = int(np.argmin(np.abs(col_x - x)))
        grid[ri, ci, 0] += x
        grid[ri, ci, 1] += y
        cnt[ri, ci] += 1

    for r in range(R):
        for c in range(C):
            if cnt[r, c] > 0:
                grid[r, c] /= cnt[r, c]
            else:
                grid[r, c] = (col_x[c], row_y[r])
    return grid


def select_best_columns(col_x: np.ndarray, k: int) -> np.ndarray:
    col_x = np.sort(col_x.astype(np.float32))
    n = len(col_x)
    if n <= k:
        return col_x
    best = None
    best_span = 1e18
    best_std = 1e18
    for i in range(0, n - k + 1):
        win = col_x[i:i+k]
        span = float(win[-1] - win[0])
        dif = np.diff(win)
        sstd = float(np.std(dif)) if len(dif) else 0.0
        # prioritize tight span + regular spacing
        score = span + 80.0 * sstd
        if score < (best_span + 80.0 * best_std):
            best = win
            best_span = span
            best_std = sstd
    return np.array(best, dtype=np.float32) if best is not None else col_x[:k]


# =========================
# Split ID vs Questions region (heuristic)
# =========================
def split_regions(centers: np.ndarray, w: int, h: int) -> Tuple[np.ndarray, np.ndarray]:
    xs = centers[:, 0]
    ys = centers[:, 1]

    # heuristics that usually work on OMR sheets
    id_mask = (xs > 0.55 * w) & (ys < 0.65 * h)
    q_mask = (ys > 0.20 * h) & (xs < 0.90 * w)

    id_c = centers[id_mask]
    q_c = centers[q_mask]

    # fallback
    if id_c.shape[0] < 25:
        id_c = centers[(xs > np.median(xs)) & (ys < np.median(ys))]
    if q_c.shape[0] < 25:
        q_c = centers[(ys > np.median(ys))]

    return id_c, q_c


def build_question_rows(q_centers: np.ndarray, col_x: np.ndarray) -> np.ndarray:
    """
    Detect real question rows without forcing question count.
    Row is valid if it hits most columns (>= k-1) using adaptive tolerances.
    """
    if q_centers.shape[0] < 10:
        return np.array([], dtype=np.float32)

    # candidate rows by Y clustering
    row_y_all = group_1d_positions(q_centers[:, 1])
    if len(row_y_all) == 0:
        return row_y_all

    k = len(col_x)

    # ---- adaptive tolerances from data (instead of fixed 12/14)
    # estimate typical bubble spacing in X and Y
    xs = np.sort(q_centers[:, 0].astype(np.float32))
    ys = np.sort(q_centers[:, 1].astype(np.float32))
    dx = np.diff(xs); dx = dx[(dx > 2) & (dx < 200)]
    dy = np.diff(ys); dy = dy[(dy > 2) & (dy < 200)]
    tol_x = max(10.0, float(np.percentile(dx, 15)) * 0.60) if len(dx) else 14.0
    tol_y = max(10.0, float(np.percentile(dy, 15)) * 0.60) if len(dy) else 12.0

    valid_rows = []
    for y0 in row_y_all:
        near = q_centers[np.abs(q_centers[:, 1] - y0) < tol_y]
        if near.shape[0] < max(2, k - 1):
            continue

        hits = 0
        for x0 in col_x:
            if np.any(np.abs(near[:, 0] - x0) < tol_x):
                hits += 1

        # âœ… Ù„Ø§ Ù†Ø¬Ø¨Ø± "ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©" â€” Ù†Ø®Ù„ÙŠÙ‡Ø§ >= k-1
        if hits >= max(2, k - 1):
            valid_rows.append(y0)

    return np.array(valid_rows, dtype=np.float32)

# =========================
# Alignment: student->key (ORB homography)
# =========================
def orb_align(student_bgr: np.ndarray, ref_bgr: np.ndarray) -> Tuple[np.ndarray, bool, int]:
    h, w = ref_bgr.shape[:2]
    orb = cv2.ORB_create(5000)

    g1 = cv2.cvtColor(student_bgr, cv2.COLOR_BGR2GRAY)
    g2 = cv2.cvtColor(ref_bgr, cv2.COLOR_BGR2GRAY)

    k1, d1 = orb.detectAndCompute(g1, None)
    k2, d2 = orb.detectAndCompute(g2, None)

    if d1 is None or d2 is None or len(k1) < 30 or len(k2) < 30:
        return cv2.resize(student_bgr, (w, h)), False, 0

    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
    matches = bf.knnMatch(d1, d2, k=2)
    good = []
    for m, n in matches:
        if m.distance < 0.75 * n.distance:
            good.append(m)

    if len(good) < 30:
        return cv2.resize(student_bgr, (w, h)), False, len(good)

    src = np.float32([k1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
    dst = np.float32([k2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)

    H, _ = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)
    if H is None:
        return cv2.resize(student_bgr, (w, h)), False, len(good)

    warped = cv2.warpPerspective(student_bgr, H, (w, h))
    return warped, True, len(good)


# =========================
# Bubble scoring (Fill + X)
# =========================
def bubble_roi(gray: np.ndarray, cx: int, cy: int, win: int = 18) -> np.ndarray:
    h, w = gray.shape[:2]
    x1 = max(0, cx - win); x2 = min(w, cx + win)
    y1 = max(0, cy - win); y2 = min(h, cy + win)
    roi = gray[y1:y2, x1:x2]
    if roi.size == 0:
        return np.zeros((1, 1), dtype=np.uint8)

    rh, rw = roi.shape
    mh = int(rh * 0.18)
    mw = int(rw * 0.18)
    inner = roi[mh:rh - mh, mw:rw - mw]
    return inner if inner.size > 0 else roi


def fill_score(roi_gray: np.ndarray) -> float:
    if roi_gray.size < 10:
        return 0.0
    g = cv2.GaussianBlur(roi_gray, (3, 3), 0)
    _, th = cv2.threshold(g, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    return float(np.mean(th > 0))


def x_mark_score(roi_gray: np.ndarray) -> float:
    g = cv2.GaussianBlur(roi_gray, (3, 3), 0)
    edges = cv2.Canny(g, 50, 150)
    min_len = max(10, int(min(roi_gray.shape) * 0.45))
    lines = cv2.HoughLinesP(
        edges, rho=1, theta=np.pi / 180,
        threshold=18, minLineLength=min_len, maxLineGap=3
    )
    if lines is None:
        return 0.0
    total = 0.0
    for x1, y1, x2, y2 in lines[:, 0]:
        total += float(np.hypot(x2 - x1, y2 - y1))
    norm = float(roi_gray.shape[0] + roi_gray.shape[1]) + 1e-9
    return total / norm


def bubble_stats(gray: np.ndarray, cx: int, cy: int, win: int = 18) -> dict:
    roi = bubble_roi(gray, cx, cy, win=win)
    return {
        "fill": float(fill_score(roi)),
        "std": float(np.std(roi)),
        "xscore": float(x_mark_score(roi)),
    }


# =========================
# Smart pick: (most filled) + ignore cancelled(X)
# and remove printed-letter baseline per row
# =========================
def pick_choice_smart(stats_list: List[dict], labels: List[str],
                      blank_norm: float,
                      close_ratio: float,
                      x_std: float,
                      x_score: float) -> Tuple[str, str, List[bool], List[float]]:

    fills = np.array([float(s["fill"]) for s in stats_list], dtype=np.float32)
    stds  = np.array([float(s["std"]) for s in stats_list], dtype=np.float32)
    xs    = np.array([float(s["xscore"]) for s in stats_list], dtype=np.float32)

    cancelled = (stds >= x_std) & (xs >= x_score)

    # baseline from the lowest half of fills (printed A/B/C/D)
    sorted_f = np.sort(fills)
    k = max(1, len(sorted_f)//2)
    baseline = float(np.median(sorted_f[:k]))

    norm = np.clip(fills - baseline, 0.0, 1.0)

    cand = [i for i in range(len(labels)) if not cancelled[i]]
    if not cand:
        return "?", "CANCELLED_ALL", cancelled.tolist(), norm.tolist()

    cand.sort(key=lambda i: norm[i], reverse=True)
    best = cand[0]
    best_v = float(norm[best])
    second_v = float(norm[cand[1]]) if len(cand) > 1 else 0.0

    if best_v < blank_norm:
        return "?", "BLANK", cancelled.tolist(), norm.tolist()

    # If close, still pick the best (you want "most shaded wins")
    if second_v > blank_norm and (best_v / (second_v + 1e-9)) < close_ratio:
        return labels[best], "OK_CLOSE", cancelled.tolist(), norm.tolist()

    return labels[best], "OK", cancelled.tolist(), norm.tolist()


# =========================
# Roster
# =========================
def load_roster(file) -> Dict[str, str]:
    if file.name.lower().endswith((".xlsx", ".xls")):
        df = pd.read_excel(file)
    else:
        df = pd.read_csv(file)

    df.columns = [c.strip().lower().replace(" ", "_") for c in df.columns]
    if "student_code" not in df.columns or "student_name" not in df.columns:
        raise ValueError("Ù…Ù„Ù Ø§Ù„Ø·Ù„Ø§Ø¨ Ù„Ø§Ø²Ù… ÙŠØ­ØªÙˆÙŠ: student_code Ùˆ student_name")

    codes = (
        df["student_code"].astype(str).str.strip()
        .str.replace(".0", "", regex=False)
        .str.zfill(4)  # fixed 4 digits
    )
    names = df["student_name"].astype(str).str.strip()
    return dict(zip(codes, names))


# =========================
# Learn template from Answer Key (AUTO, real)
# - ID fixed: 10x4
# - choices auto: 2 or 4 or 5
# - rows auto: only valid question rows
# =========================
def learn_template_from_key(key_bgr: np.ndarray) -> Tuple[LearnedTemplate, dict]:
    h, w = key_bgr.shape[:2]
    bin_img = preprocess_binary(key_bgr)
    centers = find_bubble_centers(bin_img)
    if centers.shape[0] < 30:
        raise ValueError("Ø¹Ø¯Ø¯ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ù‚Ù„ÙŠÙ„ Ø¬Ø¯Ø§Ù‹. Ø§Ø±ÙØ¹ DPI Ø£Ùˆ ØªØ£ÙƒØ¯ ÙˆØ¶ÙˆØ­ Ø§Ù„ØµÙˆØ±Ø©.")

    id_centers, q_centers = split_regions(centers, w, h)

    if id_centers.shape[0] < 30:
        raise ValueError("ÙØ´Ù„ Ø§ÙƒØªØ´Ø§Ù Ù…Ù†Ø·Ù‚Ø© ÙƒÙˆØ¯ Ø§Ù„Ø·Ø§Ù„Ø¨ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")
    if q_centers.shape[0] < 25:
        raise ValueError("ÙØ´Ù„ Ø§ÙƒØªØ´Ø§Ù Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")

    # ---- ID grid (force 10 rows, 4 cols by best window)
    id_row_y = group_1d_positions(id_centers[:, 1])
    id_col_x = group_1d_positions(id_centers[:, 0])

    # make rows ~10 by merging if needed
    if len(id_row_y) > 10:
        while len(id_row_y) > 10:
            dif = np.diff(id_row_y)
            j = int(np.argmin(dif))
            merged = (id_row_y[j] + id_row_y[j + 1]) / 2.0
            id_row_y = np.delete(id_row_y, [j, j + 1])
            id_row_y = np.sort(np.append(id_row_y, merged))
    elif len(id_row_y) < 10:
        step = float(np.median(np.diff(id_row_y))) if len(id_row_y) >= 2 else 20.0
        while len(id_row_y) < 10:
            id_row_y = np.append(id_row_y, id_row_y[-1] + step)
        id_row_y = np.sort(id_row_y)

    # choose best 4 columns
    if len(id_col_x) >= 4:
        id_col_x = select_best_columns(id_col_x, 4)
    else:
        raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù 4 Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„ÙƒÙˆØ¯. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶ÙˆØ­ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ÙƒÙˆØ¯.")

    id_grid_centers = snap_to_grid(id_centers, id_row_y, id_col_x)
    id_grid = BubbleGrid(id_row_y, id_col_x, id_grid_centers, rows=10, cols=4)

    # ---- Question columns: auto choose among {2,4,5}
    q_col_all = group_1d_positions(q_centers[:, 0])
    if len(q_col_all) < 2:
        raise ValueError("ØªØ¹Ø°Ø± Ø§ÙƒØªØ´Ø§Ù Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª.")

    best_cols = None
    best_score = 1e18
    for k in [2, 4, 5]:
        if len(q_col_all) < k:
            continue
        cols_k = select_best_columns(q_col_all, k)
        span = float(cols_k[-1] - cols_k[0])
        dif = np.diff(cols_k)
        sstd = float(np.std(dif)) if len(dif) else 0.0
        score = span + 80.0 * sstd
        if score < best_score:
            best_score = score
            best_cols = cols_k

    if best_cols is None:
        raise ValueError("Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (2/4/5).")

    q_col_x = best_cols
    num_choices = int(len(q_col_x))

    # ---- Question rows: real rows only (must hit all chosen columns)
    q_row_y = build_question_rows(q_centers, q_col_x)
    if len(q_row_y) < 3:
        raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ØµÙÙˆÙ Ø£Ø³Ø¦Ù„Ø© ÙƒØ§ÙÙŠØ©. Ø±Ø¨Ù…Ø§ Ø§Ù„ØµÙØ­Ø© Ù…Ù‚ØµÙˆØµØ© Ø£Ùˆ ØºÙŠØ± ÙˆØ§Ø¶Ø­Ø©.")

    q_grid_centers = snap_to_grid(q_centers, q_row_y, q_col_x)
    q_grid = BubbleGrid(q_row_y, q_col_x, q_grid_centers, rows=len(q_row_y), cols=num_choices)

    template = LearnedTemplate(
        ref_bgr=key_bgr, ref_w=w, ref_h=h,
        id_grid=id_grid, q_grid=q_grid,
        num_q=len(q_row_y),
        num_choices=num_choices,
        id_rows=10, id_digits=4
    )

    dbg = {
        "centers_total": int(centers.shape[0]),
        "id_centers": int(id_centers.shape[0]),
        "q_centers": int(q_centers.shape[0]),
        "id_rows": 10,
        "id_digits": 4,
        "q_rows": int(len(q_row_y)),
        "q_cols": int(num_choices),
    }
    return template, dbg


# =========================
# Extract Answer Key from template (SMART)
# =========================
def extract_answer_key(template: LearnedTemplate) -> Tuple[Dict[int, str], pd.DataFrame, dict]:
    gray = cv2.cvtColor(template.ref_bgr, cv2.COLOR_BGR2GRAY)
    choices = list("ABCDEFGH"[:template.num_choices])

    # thresholds (stable defaults)
    blank_norm = 0.06
    close_ratio = 1.12
    x_std_key = 18.0
    x_score_key = 0.90

    key = {}
    dbg_rows = []

    for r in range(template.q_grid.rows):
        stats = []
        for c in range(template.q_grid.cols):
            cx, cy = template.q_grid.centers[r, c]
            stats.append(bubble_stats(gray, safe_int(cx), safe_int(cy), win=18))

        ans, status, cancelled, normfills = pick_choice_smart(
            stats, choices,
            blank_norm=blank_norm,
            close_ratio=close_ratio,
            x_std=x_std_key,
            x_score=x_score_key
        )

        if status.startswith("OK"):
            key[r + 1] = ans

        dbg_rows.append(
            [r + 1, ans, status, cancelled] +
            [round(float(x), 3) for x in normfills] +
            [round(float(s["fill"]), 3) for s in stats] +
            [round(float(s["std"]), 1) for s in stats] +
            [round(float(s["xscore"]), 2) for s in stats]
        )

    df_dbg = pd.DataFrame(
        dbg_rows,
        columns=(["Q", "Picked", "Status", "CancelledFlags"] +
                 [f"norm_{c}" for c in choices] +
                 [f"fill_{c}" for c in choices] +
                 [f"std_{c}" for c in choices] +
                 [f"x_{c}" for c in choices])
    )

    params = {
        "choices": choices,
        "blank_norm": blank_norm,
        "close_ratio": close_ratio,
        "x_std_student": 22.0,
        "x_score_student": 1.2,
        "x_std_key": x_std_key,
        "x_score_key": x_score_key,
    }
    return key, df_dbg, params


# =========================
# Read student ID (10x4)
# =========================
def read_student_id(template: LearnedTemplate, gray: np.ndarray) -> str:
    digits = []
    for c in range(4):
        fills = []
        for r in range(10):
            cx, cy = template.id_grid.centers[r, c]
            roi = bubble_roi(gray, safe_int(cx), safe_int(cy), win=16)
            fills.append(fill_score(roi))

        idx = np.argsort(fills)[::-1]
        best = int(idx[0])
        second = int(idx[1]) if len(idx) > 1 else best

        best_f = float(fills[best])
        second_f = float(fills[second])

        # conservative decision
        if best_f < 0.08 or (best_f - second_f) < 0.04:
            digit = "X"
        else:
            digit = str(best)  # row index corresponds to digit 0..9

        digits.append(digit)

    return "".join(digits)


# =========================
# Read student answers (SMART, your rules)
# =========================
def read_student_answers(template: LearnedTemplate, gray: np.ndarray, params: dict) -> pd.DataFrame:
    choices = params["choices"]

    rows = []
    for r in range(template.q_grid.rows):
        stats = []
        for c in range(template.q_grid.cols):
            cx, cy = template.q_grid.centers[r, c]
            stats.append(bubble_stats(gray, safe_int(cx), safe_int(cy), win=18))

        ans, status, cancelled, normfills = pick_choice_smart(
            stats, choices,
            blank_norm=float(params["blank_norm"]),
            close_ratio=float(params["close_ratio"]),
            x_std=float(params["x_std_student"]),
            x_score=float(params["x_score_student"])
        )

        rows.append([r + 1, ans, status, cancelled] + [round(float(x), 3) for x in normfills])

    return pd.DataFrame(rows, columns=["Q", "Picked", "Status", "CancelledFlags"] + [f"norm_{c}" for c in choices])


# =========================
# Main UI
# =========================
def main():
    st.set_page_config(page_title="AUTO OMR (Real Training)", layout="wide")
    st.title("âœ… OMR Ø°ÙƒÙŠ: Ø§ÙƒØªØ´Ø§Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© + Ø¹Ø¯Ø¯ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (2/4/5) + Ù‚Ø§Ø¹Ø¯Ø© X")

    if "trained" not in st.session_state:
        st.session_state.trained = False
        st.session_state.template = None
        st.session_state.answer_key = None
        st.session_state.key_dbg = None
        st.session_state.params = None
        st.session_state.preview_img = None
        st.session_state.train_dbg = None

    col1, col2, col3 = st.columns(3)
    with col1:
        roster_file = st.file_uploader("ğŸ“‹ Ù…Ù„Ù Ø§Ù„Ø·Ù„Ø§Ø¨ (Excel/CSV)", type=["xlsx", "xls", "csv"])
    with col2:
        key_file = st.file_uploader("ğŸ”‘ Answer Key (PDF/ØµÙˆØ±Ø©)", type=["pdf", "png", "jpg", "jpeg"])
    with col3:
        sheets_file = st.file_uploader("ğŸ“š Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ø·Ù„Ø§Ø¨ (PDF/ØµÙˆØ±Ø©)", type=["pdf", "png", "jpg", "jpeg"])

    dpi = st.selectbox("DPI Ù„Ù„Ù€ PDF", [200, 250, 300, 350, 400], index=2)
    debug = st.checkbox("Debug (Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„)", value=True)

    if not key_file:
        st.info("Ø§Ø±ÙØ¹ Answer Key Ø£ÙˆÙ„Ø§Ù‹.")
        return

    if (not st.session_state.trained) or st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ø£Ù†Ø³Ø±"):
        try:
            key_pages = load_pages(read_bytes(key_file), key_file.name, dpi=int(dpi))
            key_bgr = pil_to_bgr(key_pages[0])

            template, train_dbg = learn_template_from_key(key_bgr)
            answer_key, df_key_dbg, params = extract_answer_key(template)

            # preview overlay
            vis = key_bgr.copy()
            for r in range(template.q_grid.rows):
                for c in range(template.q_grid.cols):
                    x, y = template.q_grid.centers[r, c]
                    cv2.circle(vis, (safe_int(x), safe_int(y)), 6, (0, 255, 0), 2)
            for r in range(template.id_grid.rows):
                for c in range(template.id_grid.cols):
                    x, y = template.id_grid.centers[r, c]
                    cv2.circle(vis, (safe_int(x), safe_int(y)), 6, (0, 0, 255), 2)

            st.session_state.template = template
            st.session_state.answer_key = answer_key
            st.session_state.key_dbg = df_key_dbg
            st.session_state.params = params
            st.session_state.preview_img = vis
            st.session_state.train_dbg = train_dbg
            st.session_state.trained = True

            st.success("âœ… ØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø®ÙŠØ§Ø±Ø§Øª ÙˆØ§Ù„ÙƒÙˆØ¯) Ø¨Ù†Ø¬Ø§Ø­.")
        except Exception as e:
            st.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: {e}")
            with st.expander("ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ (Traceback)"):
                st.code(traceback.format_exc())
            st.session_state.trained = False
            return

    template = st.session_state.template
    answer_key = st.session_state.answer_key
    df_key_dbg = st.session_state.key_dbg
    params = st.session_state.params

    st.markdown("---")
    st.subheader("ğŸ“Œ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù Ù‚Ø¨Ù„ Ø§Ù„ØªØµØ­ÙŠØ­")

    cA, cB, cC, cD = st.columns(4)
    with cA:
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØªØ´Ù", int(template.num_q))
    with cB:
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´Ù", int(template.num_choices))
    with cC:
        st.metric("Ø®Ø§Ù†Ø§Øª ÙƒÙˆØ¯ Ø§Ù„Ø·Ø§Ù„Ø¨", 4)
    with cD:
        st.metric("ØµÙÙˆÙ ÙƒÙˆØ¯ Ø§Ù„Ø·Ø§Ù„Ø¨", 10)

    st.caption(f"Detected centers: {st.session_state.train_dbg}")

    st.markdown("### ğŸ”‘ Answer Key Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬")
    st.json(answer_key)

    if debug:
        st.markdown("### Ø¬Ø¯ÙˆÙ„ Debug (Ù…Ù‡Ù… Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙŠ ÙØ´Ù„Øª)")
        st.dataframe(df_key_dbg, width="stretch", height=450)
        st.image(bgr_to_rgb(st.session_state.preview_img), caption="Green=Questions, Red=ID", width="stretch")

    st.markdown("---")
    st.subheader("âœ… Ø§Ù„ØªØµØ­ÙŠØ­")

    if not roster_file or not sheets_file:
        st.warning("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø·Ù„Ø§Ø¨ + Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ø·Ù„Ø§Ø¨ Ù„Ù„Ø¨Ø¯Ø¡.")
        return

    # roster
    try:
        roster = load_roster(roster_file)
        st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø·Ù„Ø§Ø¨: {len(roster)}")
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ Ù…Ù„Ù Ø§Ù„Ø·Ù„Ø§Ø¨: {e}")
        return

    if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø¢Ù†", type="primary"):
        try:
            pages = load_pages(read_bytes(sheets_file), sheets_file.name, dpi=int(dpi))
            if not pages:
                st.error("ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ø·Ù„Ø§Ø¨")
                return

            results = []
            prog = st.progress(0)

            for i, pil_page in enumerate(pages, start=1):
                page_bgr = pil_to_bgr(pil_page)
                aligned, ok, good = orb_align(page_bgr, template.ref_bgr)
                gray = cv2.cvtColor(aligned, cv2.COLOR_BGR2GRAY)

                code = read_student_id(template, gray)
                code = str(code).zfill(4)
                name = roster.get(code, "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")

                df_ans = read_student_answers(template, gray, params)

                correct = 0
                total = len(answer_key)

                for _, row in df_ans.iterrows():
                    q = int(row["Q"])
                    if q not in answer_key:
                        continue
                    if not str(row["Status"]).startswith("OK"):
                        continue
                    if row["Picked"] == answer_key[q]:
                        correct += 1

                pct = (correct / total * 100.0) if total else 0.0
                results.append({
                    "page": i,
                    "aligned_ok": ok,
                    "good_matches": good,
                    "student_code": code,
                    "student_name": name,
                    "score": correct,
                    "total": total,
                    "percentage": round(pct, 2),
                    "status": "Ù†Ø§Ø¬Ø­ âœ“" if pct >= 50 else "Ø±Ø§Ø³Ø¨ âœ—",
                })

                prog.progress(int(i / len(pages) * 100))

            df_res = pd.DataFrame(results)
            st.success("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØµØ­ÙŠØ­")
            st.dataframe(df_res, width="stretch", height=420)

            out = io.BytesIO()
            df_res.to_excel(out, index=False, engine="openpyxl")
            st.download_button(
                "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Excel",
                data=out.getvalue(),
                file_name="results.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width="stretch",
            )

        except Exception as e:
            st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØµØ­ÙŠØ­: {e}")
            with st.expander("ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ (Traceback)"):
                st.code(traceback.format_exc())


if __name__ == "__main__":
    main()
